{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7908281,"sourceType":"datasetVersion","datasetId":4644788}],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"SEED = 42","metadata":{"execution":{"iopub.status.busy":"2024-04-19T18:31:31.699052Z","iopub.execute_input":"2024-04-19T18:31:31.700056Z","iopub.status.idle":"2024-04-19T18:31:31.749296Z","shell.execute_reply.started":"2024-04-19T18:31:31.699992Z","shell.execute_reply":"2024-04-19T18:31:31.747983Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Importing Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport plotly.express as px\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.model_selection import train_test_split, GridSearchCV","metadata":{"execution":{"iopub.status.busy":"2024-04-19T18:31:31.751415Z","iopub.execute_input":"2024-04-19T18:31:31.751887Z","iopub.status.idle":"2024-04-19T18:31:36.425137Z","shell.execute_reply.started":"2024-04-19T18:31:31.751849Z","shell.execute_reply":"2024-04-19T18:31:36.423828Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"input_file_path = '/kaggle/input/trytry/final_ct.csv'","metadata":{"execution":{"iopub.status.busy":"2024-04-19T18:31:36.426545Z","iopub.execute_input":"2024-04-19T18:31:36.427151Z","iopub.status.idle":"2024-04-19T18:31:36.431862Z","shell.execute_reply.started":"2024-04-19T18:31:36.427118Z","shell.execute_reply":"2024-04-19T18:31:36.430997Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### **Handling Null Values and Removing Outliers**","metadata":{}},{"cell_type":"code","source":"# Filter out any warnings\nwarnings.filterwarnings(\"ignore\")\n\ndf = pd.read_csv(input_file_path)\n\ndf.dropna(inplace=True)\n\n\nlocation = ['Latitude', 'Longitude']\ngrow_time = [ 'Harvest year', 'Sowing month','Harvesting month']\nenvironmental = ['P', 'E', 'PB', 'Tave']\ncategorical_cols = ['Crop', 'Fertilization CT ', 'N input', 'ST']\n\n\ndef UVA_numeric(data, var_group):\n  '''\n  Univariate_Analysis_numeric\n  takes a group of variables (INTEGER and FLOAT) and plot/print all the descriptives and properties along with KDE.\n\n  Runs a loop: calculate all the descriptives of i(th) variable and plot/print it\n  '''\n\n  size = len(var_group)\n  plt.figure(figsize = (7*size,3), dpi = 100)\n  \n  #looping for each variable\n  for j,i in enumerate(var_group):\n    \n    # calculating descriptives of variable\n    mini = data[i].min()\n    maxi = data[i].max()\n    ran = data[i].max()-data[i].min()\n    mean = data[i].mean()\n    median = data[i].median()\n    st_dev = data[i].std()\n    skew = data[i].skew()\n    kurt = data[i].kurtosis()\n\n    # calculating points of standard deviation\n    points = [mean-st_dev, mean+st_dev]\n\n    #Plotting the variable with every information\n    plt.subplot(1,size,j+1)\n    sns.kdeplot(data[i], shade=True)\n    sns.lineplot(x = points, y = [0,0], color = 'black', label = \"std_dev\")\n    sns.scatterplot(x = [mini,maxi], y = [0,0], color = 'orange', label = \"min/max\")\n    sns.scatterplot(x = [mean], y = [0], color = 'red', label = \"mean\")\n    sns.scatterplot(x = [median], y = [0], color = 'blue', label = \"median\")\n    plt.xlabel('{}'.format(i), fontsize = 20)\n    plt.ylabel('density')\n    plt.title('std_dev = {}; kurtosis = {};\\nskew = {}; range = {}\\nmean = {}; median = {}'.format((round(points[0],2),round(points[1],2)),\n                                                                                                   round(kurt,2),\n                                                                                                   round(skew,2),\n                                                                                                   (round(mini,2),round(maxi,2),round(ran,2)),\n                                                                                                   round(mean,2),\n                                                                                                   round(median,2)))\n\n\n\n\n\ndef UVA_category(data, var_group):\n    '''\n    Univariate_Analysis_categorical\n    takes a group of variables (category) and plot/print all the value_counts and barplot.\n    '''\n    # setting figure_size\n    size = len(var_group)\n    plt.figure(figsize=(7*size, 5), dpi=100)\n\n    # for every variable\n    for j, i in enumerate(var_group):\n        norm_count = data[i].value_counts(normalize=True)\n        n_uni = data[i].nunique()\n\n        # Plotting the variable with every information\n        plt.subplot(1, size, j + 1)\n        sns.barplot(x=norm_count, y=norm_count.index, order=norm_count.index)\n        plt.xlabel('fraction/percent', fontsize=20)\n        plt.ylabel('{}'.format(i), fontsize=20)\n        plt.title('n_uniques = {} \\n value counts \\n {};'.format(n_uni, norm_count))\n\n    plt.show()\n\n# Example usage:\n# Assuming 'data' is your DataFrame and 'var_group' is a list of column names\n# UVA_category(data, var_group)\n\n\n\n\n# custom function for easy outlier analysis\n\ndef UVA_outlier(data, var_group, include_outlier = True):\n  '''\n  Univariate_Analysis_outlier:\n  takes a group of variables (INTEGER and FLOAT) and plot/print boplot and descriptives\\n\n  Runs a loop: calculate all the descriptives of i(th) variable and plot/print it \\n\\n\n\n  data : dataframe from which to plot from\\n\n  var_group : {list} type Group of Continuous variables\\n\n  include_outlier : {bool} whether to include outliers or not, default = True\\n\n  '''\n\n  size = len(var_group)\n  plt.figure(figsize = (7*size,4), dpi = 100)\n  \n  #looping for each variable\n  for j,i in enumerate(var_group):\n    \n    # calculating descriptives of variable\n    quant25 = data[i].quantile(0.25)\n    quant75 = data[i].quantile(0.75)\n    IQR = quant75 - quant25\n    med = data[i].median()\n    whis_low = quant25-(1.5*IQR)\n    whis_high = quant75+(1.5*IQR)\n\n    # Calculating Number of Outliers\n    outlier_high = len(data[i][data[i]>whis_high])\n    outlier_low = len(data[i][data[i]<whis_low])\n\n    if include_outlier == True:\n      #Plotting the variable with every information\n      plt.subplot(1,size,j+1)\n      sns.boxplot(data[i], orient=\"v\")\n      plt.ylabel('{}'.format(i))\n      plt.title('With Outliers\\nIQR = {}; Median = {} \\n 2nd,3rd  quartile = {};\\n Outlier (low/high) = {} \\n'.format(\n                                                                                                   round(IQR,2),\n                                                                                                   round(med,2),\n                                                                                                   (round(quant25,2),round(quant75,2)),\n                                                                                                   (outlier_low,outlier_high)\n                                                                                                   ))\n      \n    else:\n      # replacing outliers with max/min whisker\n      data2 = data[var_group][:]\n      data2[i][data2[i]>whis_high] = whis_high+1\n      data2[i][data2[i]<whis_low] = whis_low-1\n      \n      # plotting without outliers\n      plt.subplot(1,size,j+1)\n      sns.boxplot(data2[i], orient=\"v\")\n      plt.ylabel('{}'.format(i))\n      plt.title('Without Outliers\\nIQR = {}; Median = {} \\n 2nd,3rd  quartile = {};\\n Outlier (low/high) = {} \\n'.format(\n                                                                                                   round(IQR,2),\n                                                                                                   round(med,2),\n                                                                                                   (round(quant25,2),round(quant75,2)),\n                                                                                                   (outlier_low,outlier_high)\n                                                                                                   ))\n\n\n\ntrimmed_df = df.copy()\n\nimport matplotlib.pyplot as plt\n\ndef UVA_outlier_remove(data, var_group, trimmed_df):\n    size = len(var_group)\n    plt.figure(figsize=(7*size, 4), dpi=100)\n    for i in var_group:\n        # calculating descriptives of variable\n        quant25 = data[i].quantile(0.25)\n        quant75 = data[i].quantile(0.75)\n        IQR = quant75 - quant25\n        med = data[i].median()\n        whis_low = quant25 - (1.5 * IQR)\n        whis_high = quant75 + (1.5 * IQR)\n\n        # Calculating Number of Outliers\n        outlier_high = len(data[i][data[i] > whis_high])\n        outlier_low = len(data[i][data[i] < whis_low])\n\n        # Filtering outliers from trimmed_df\n        trimmed_df = trimmed_df[(trimmed_df[i] < whis_high) & (trimmed_df[i] > whis_low)]\n    return trimmed_df\n\n\ntrimmed_df = UVA_outlier_remove(df, environmental, trimmed_df)\n\ntrimmed_df = UVA_outlier_remove(trimmed_df, location, trimmed_df)\n\ntrimmed_df = UVA_outlier_remove(trimmed_df, grow_time, trimmed_df)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T18:31:36.435574Z","iopub.execute_input":"2024-04-19T18:31:36.436281Z","iopub.status.idle":"2024-04-19T18:31:36.585131Z","shell.execute_reply.started":"2024-04-19T18:31:36.436246Z","shell.execute_reply":"2024-04-19T18:31:36.584043Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 2800x400 with 0 Axes>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1400x400 with 0 Axes>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 2100x400 with 0 Axes>"},"metadata":{}}]},{"cell_type":"markdown","source":"### **Handling Categorical Variables**","metadata":{}},{"cell_type":"code","source":"categorical_columns = trimmed_df.select_dtypes(include=['object','category']).columns.tolist()\none_hot_encoded_df = pd.get_dummies(trimmed_df, columns=categorical_columns)\n# Selecting features (X) and target (y)\n# Extracting features (X)\nX = one_hot_encoded_df.drop(columns=['Yield of CT'])\n# Extracting target variable (y)\ny = one_hot_encoded_df['Yield of CT']","metadata":{"execution":{"iopub.status.busy":"2024-04-19T18:31:36.586618Z","iopub.execute_input":"2024-04-19T18:31:36.587176Z","iopub.status.idle":"2024-04-19T18:31:36.609245Z","shell.execute_reply.started":"2024-04-19T18:31:36.587145Z","shell.execute_reply":"2024-04-19T18:31:36.607827Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### **Train/Test Split**","metadata":{}},{"cell_type":"code","source":"# Splitting the dataset into train and test sets (80% train, 20% test)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T18:31:36.610894Z","iopub.execute_input":"2024-04-19T18:31:36.611534Z","iopub.status.idle":"2024-04-19T18:31:36.619992Z","shell.execute_reply.started":"2024-04-19T18:31:36.611500Z","shell.execute_reply":"2024-04-19T18:31:36.618962Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### **Normalize data**","metadata":{}},{"cell_type":"code","source":"scaler = StandardScaler()\nX_train_normalized = scaler.fit_transform(X_train)\nX_test_normalized = scaler.transform(X_test)\n#fit_transform() on our X_train data, but only use transform() on our X_test data.\n#Not doing this can cause “data leakage” and may give away the answer to our model.","metadata":{"execution":{"iopub.status.busy":"2024-04-19T18:31:36.621168Z","iopub.execute_input":"2024-04-19T18:31:36.622030Z","iopub.status.idle":"2024-04-19T18:31:36.650617Z","shell.execute_reply.started":"2024-04-19T18:31:36.621995Z","shell.execute_reply":"2024-04-19T18:31:36.649637Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"y_train = y_train.values.reshape(-1,1)\ny_test = y_test.values.reshape(-1,1)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T18:31:36.651871Z","iopub.execute_input":"2024-04-19T18:31:36.652587Z","iopub.status.idle":"2024-04-19T18:31:36.657964Z","shell.execute_reply.started":"2024-04-19T18:31:36.652549Z","shell.execute_reply":"2024-04-19T18:31:36.656808Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### **Hyperparameter Tuning (GridSearchCV)**","metadata":{}},{"cell_type":"code","source":"# Create a KNN regressor\nknn_regressor = KNeighborsRegressor()\n\n# Define the grid of parameters to search\nparam_grid = {\n    'n_neighbors': [3, 5, 7,10,15],\n    'p': [1, 2]  # L1 and L2 distances\n}\n\n# Perform GridSearchCV\ngrid_search = GridSearchCV(knn_regressor, param_grid, cv=5, scoring='neg_mean_squared_error')\ngrid_search.fit(X_train_normalized, y_train)\n\n\n# Print best parameters\nprint(\"Best parameters found:\")\nprint(grid_search.best_params_)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T18:31:36.662183Z","iopub.execute_input":"2024-04-19T18:31:36.662735Z","iopub.status.idle":"2024-04-19T18:31:37.541340Z","shell.execute_reply.started":"2024-04-19T18:31:36.662654Z","shell.execute_reply":"2024-04-19T18:31:37.540302Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Best parameters found:\n{'n_neighbors': 3, 'p': 1}\n","output_type":"stream"}]},{"cell_type":"code","source":"# Get the best model\nbest_model = grid_search.best_estimator_\npredictions = best_model.predict(X_test_normalized)\n    \nmse = mean_squared_error(y_test, predictions)\nprint(\"Root Mean Squared Error:\", np.sqrt(mse))","metadata":{"execution":{"iopub.status.busy":"2024-04-19T18:31:37.545556Z","iopub.execute_input":"2024-04-19T18:31:37.546426Z","iopub.status.idle":"2024-04-19T18:31:37.594103Z","shell.execute_reply.started":"2024-04-19T18:31:37.546387Z","shell.execute_reply":"2024-04-19T18:31:37.593104Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Root Mean Squared Error: 1811.8070872676458\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Custom Implementation**","metadata":{}},{"cell_type":"code","source":"#define distance metrics\ndef euclidean_distance(x1, x2):\n    return np.sqrt(np.sum((x1 - x2) ** 2))\ndef manhattan_distance(x1, x2):\n    return np.sum(np.abs(x1 - x2))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-19T18:31:37.598425Z","iopub.execute_input":"2024-04-19T18:31:37.599206Z","iopub.status.idle":"2024-04-19T18:31:37.609982Z","shell.execute_reply.started":"2024-04-19T18:31:37.599165Z","shell.execute_reply":"2024-04-19T18:31:37.608049Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class KNNRegression:\n    def __init__(self, k, p = 2):\n        self.k = k\n        self.p  = p\n\n    def fit(self, X_train, y_train):\n        self.X_train = X_train\n        self.y_train = y_train\n\n    def predict(self, X_test):\n        y_pred = []\n        for x in X_test:\n            if self.p == 2:\n                distances = [euclidean_distance(x, x_train) for x_train in self.X_train]\n            elif self.p == 1:\n                distances = [manhattan_distance(x, x_train) for x_train in self.X_train]\n            nearest_neighbors = np.argsort(distances)[:self.k]  #select top k shortest distances\n            y_pred.append(np.mean(self.y_train[nearest_neighbors]))\n        return np.array(y_pred)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-19T18:31:37.612288Z","iopub.execute_input":"2024-04-19T18:31:37.612678Z","iopub.status.idle":"2024-04-19T18:31:37.627187Z","shell.execute_reply.started":"2024-04-19T18:31:37.612646Z","shell.execute_reply":"2024-04-19T18:31:37.625980Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Instantiate and train the KNNRegressor\n#Using above chosen hyperparameters\nmyknn_regressor = KNNRegression(k=3,p=1)\nmyknn_regressor.fit(X_train_normalized, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T18:31:37.628779Z","iopub.execute_input":"2024-04-19T18:31:37.629325Z","iopub.status.idle":"2024-04-19T18:31:37.645615Z","shell.execute_reply.started":"2024-04-19T18:31:37.629281Z","shell.execute_reply":"2024-04-19T18:31:37.643987Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# **Predict on Test Data**","metadata":{}},{"cell_type":"code","source":"# Predict on the test data\ny_pred = myknn_regressor.predict(X_test_normalized)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T18:31:37.647159Z","iopub.execute_input":"2024-04-19T18:31:37.648135Z","iopub.status.idle":"2024-04-19T18:31:50.418184Z","shell.execute_reply.started":"2024-04-19T18:31:37.648098Z","shell.execute_reply":"2024-04-19T18:31:50.416989Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"mse = mean_squared_error(y_test, y_pred)\nprint(\"Root Mean Squared Error:\", np.sqrt(mse))","metadata":{"execution":{"iopub.status.busy":"2024-04-19T18:31:50.419838Z","iopub.execute_input":"2024-04-19T18:31:50.420219Z","iopub.status.idle":"2024-04-19T18:31:50.426649Z","shell.execute_reply.started":"2024-04-19T18:31:50.420178Z","shell.execute_reply":"2024-04-19T18:31:50.425771Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Root Mean Squared Error: 1784.1738899065454\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}